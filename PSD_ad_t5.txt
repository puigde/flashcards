Model de programació MapReduce, Map: la seva entry és una porció de dades indentificats per una clau; Su resultado es un resultado (parcial) identificado por una clave que puede ser distinta a la de entrada;; Reduce: Es opcional y ejecuta la agregación de los resultados parciales (generados por la función de map);Su entrada es una lista de valores generados por el map que tienen la misma clave, ,
Propietats d'un Framework MapReduce, Oferiments: interfície pel particionament; gestió d'execució i paralel·lisme; integracció amb l'emmagatzematge de dades;; Pensats per executar-se en datacenter/clouds de grans dimensions;; Estabilitat i tolerància als fallos;; P.ex: Apache Hadoop; Oferiments; Dimensions; Tolerància; Exemple;;, ,
Components de l'Aquitectura Apache Hadoop, Resource Manager (master) i Node Manager (slaves) que creen els containers de les aplicacions sota petició del resource manager; MRAppMaster s'executa en un container i comprova l'estat de les tasques reiniciant les que han fallat, Resource Manager; Node Manager; MRAppMaster,
Components de l'arquitectura HDFS (Hadoop File System), Namenode: Master; Implementa l'espai de nom i l'assignació de blocs a Datanodes. Datanodes: Slave; Implementa els accessos a blocs, Namenode i Datanode, 
map combiner i reducer, map: rep un conjunt de <clau;valor> i produeix com a sortida un altre conjunts <clau'; valor'>; es llença un mapper per a cada partició de les dades d'entrada (InputSplit). combiner: Función opcional para agrupar valores de salida con la misma key de los mappers locales (para minimizar mensajes a los reducers). El input es la salida de los mappers; y el output los pares <key; lista_valores>. reducer: La salida del map (o de los combiner) son ordenados y particionados para mandárselos a los reducers; El número de reducers no depende de los datos de entrada y es un parámetro configurable (se puede hacer que sean 0 si no se necesita fase de reduce); El programador puede decidir cómo hacer las particiones para cada reducer si implementa su propio partitioner, ,
Arquitectura Apache Spark, Esquema master-slave: el driver és el master:: analitza codi i demana recursos ; planifica tasks i monitoritza execució. executors son els slaves:: s'encarreguen d'executar tasks. cluster manager:: s'encarrega d'assignar els recursos i crear els processos executors en els nodes slave; driver executors i cluster manager,Resource scheduling en clusters tipus, estàtic o standalone,
Passos per a crear un programa Apache Spark, 1.Creació spark context; 2.Creació RDD Input; 3.Operacions sobre les particions dels RDD (transformacions i accions); [Lazy Evaluation: es retrassa el moment del càlcul fins que fa falta al aplicar una action], ,
Transformations i Actions, Transformations: càlculs sobre un RDD que genera un altre RDD -> dos tipus:: Wide (cal intercanviar informació entre diversos workers); Narrow (totes les dades necessàries estan a la mateixa partició);; Actions: generen un resultat que es guarda en l'emmagatzematge o que es mostra en pantalla (una vegada finalitzades les transformacions desencadenen que s'inicii el càlcul) [per defecte cada vegada que s'executa una action sobre un RDD es torna a calcular l'RDD; es pot evitar usant el mètode persist, ,
Transformació Map, rep un funció i retorna un nou RDD resultat d'aplicar la funció rebuda sobre l'RDD d'entry, , 
Transformació flatMap, rep una funció i retorna un nou RDD resultant d'aplicar la funció sobre l'RDD d'entry però ara cada element pot convertir-se en 0 o diversos elements a la sortida, ,
Transformació filter, crea un RDD resultat del filtratge de l'RDD d'entrada, , 
Transformació reduceByKey, rep una funció com a paràmetre; l'entry han de ser parells clau valor; agrupa per clau i aplica la funció sobre els valors, , 
Transformació aggregateByKey, rep un valor inicial de pair i dues funcions; les dues s'apliquen sobre el valor; cal utilitzar aquesta transformació si el resultat de sortida és de tipus diferent al d'entry, , 
Transformació sortByKey, rep com a paràmetres l'ordre (asc. o desc); el nombre de particions i el criteri d'ordenació, , 
Accions collect count take takeOrdered reduce, collect saveAsTextFile: no rep paràmetres i retorna al driver el RDD; count no rep paràmetres i retorna al driver el nombre d'elements que té el RDD; take: rep un enter com a paràmetre i retorna els n primers elements del RDD; takeOrdered: rep el nombre d'elements i un criteri d'ordenació i retorna els primers n elements acord el criteri especificats; reduce: rep com a paràmetre una funció i pren com a entry dos arguments i els hi aplcica la funció rebuda com a paràmetre per convertir-los en un sol valor; mou totes les dades al mateix node (RDD d'entry); saveAsTextFile: rep el nom d'un directori que no ha d'existir; cada worker escriu la part de dades que ha generat en un fitxer diferent d'aquest directori, ,
Pros&Cons de les bases de dades NoSQL, Pros: Tolerància als fallos; Suport de dades no estructurades; executable sobre comodity hardware [hardwar comú barat]; escalables horitzontalment; queries simples però ràpides. Cons: no hi ha llenguatge estàndard; eficiència depèn de l'organització de les dades, , 
Cassandra general info, Basada en DynamoDB [database d'Amazon]; clau-valor [column oriented]; no fa falta definir un esquema ni que totes les dades tinguin la mateixa estructura; Peer-to-peer architecture; Basada en [] Funcionament dels esquemes i Arquitectura, , 
Model de dades de Cassandra, Primary Key: valors [composta d'una partition key i n clustering keys]; La unitat per a cada petició és la partició [totes les rows que comparteixen partition key], , 
Teorema del CAP, Un sistema distribuït no pot manternir al mateix temps les següents 3 propietats: Consistency Availability i Partition Tolerance. Cassandra prioritza AP, , 
Nivells de consistència de Cassandra concepte i tipus, un nivell de consistència determina quants nodes amb una rèplica de les dades han de notificar que han acabat l'operació abans de que el coordinador la doni per acabada; ALL: tots; QUORUM: si hi ha majoria considerant tots els datacenters; LOCAL_QUORUM: si hi ha majoria considerant el nombre de duplicacions locals; EACH_QUORUM: si hi ha quorum local a cadascun dels datacenters d'escriptures acabades [no suportat per a lectures]; ANY: almenys una rèplica en el coordinador; ONE [default]; LOCAL_ONE; etc., ,
Objectius al definir el model de dades, Distribuir les dades uniformement entre els nodes per maximitzar el paralelisme; reduir el nombre de particions llegides per cada query; no importa la duplicació; les condicions de filtratge son més eficients quan involucren a la partition key [menys particions a consultar habitualment], , 